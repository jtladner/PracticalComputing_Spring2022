{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# This notebook will introduce you some of the basic functionality of the 3rd party module called *pandas*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First things first, you need to import the module before you can use it\n",
    "\n",
    "import pandas as pd             # This is the standard way that pandas is imported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series\n",
    "\n",
    "## Series are 1-dimensional labeled arrays\n",
    "## And, if you ever extract a column or row from a Dataframe, it will be returned as a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series can be generated using the \"Series\" function in pandas \n",
    "# and they can be generated from many different starting places\n",
    "\n",
    "# Here, I'm converting a list into a Series\n",
    "# Note: the labels/indexes (left column) are assigned by default in this case (0,1,2,3)\n",
    "l = [112, 678, 459, 1078]\n",
    "s1 = pd.Series(l)\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I'm generating a series with the same values, but I'm explicitly providing labels/indexes\n",
    "s2 = pd.Series(l, index = [\"value1\", \"value2\", \"value3\", \"value4\"])\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here, I'm generating the same series, but with a dictionary as a starting place\n",
    "d = {\"value1\":112, \"value2\":678, \"value3\":459, \"value4\":1078}\n",
    "s3 = pd.Series(d)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can access items from within Series in two ways\n",
    "\n",
    "# One if to access by location, similar to list indexing and slicing\n",
    "# This will work the same for all of the series we've generated\n",
    "print(\"3rd item from series 1:\", s1[2])\n",
    "print(\"3rd item from series 2:\", s2[2],)\n",
    "\n",
    "# You can also create a new series that is a subset of the existing series, using slicing\n",
    "s4 = s3[:2]\n",
    "print(\"\\ns4\\n\", s4)\n",
    "s5 = s3[2:]\n",
    "print(\"\\ns5\\n\", s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also access items by their indexes/labels\n",
    "print(\"2nd item from series 2 using position:\", s1[1])\n",
    "print(\"2nd item from series 2 using index/label:\", s2[\"value2\"])\n",
    "\n",
    "# And, if your labels conform to the requirements of python variables, \n",
    "# they can also be specified using dot notation\n",
    "print(\"2nd item from series 2 using index/label:\", s2.value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also easily add new values to series\n",
    "# Or modify existing values using syntax that should already be familiar\n",
    "\n",
    "print(\"Prior to manipulation:\\n\")\n",
    "print(s2)\n",
    "\n",
    "# Adding a new value, with syntax that is the same as adding a key:value to a dictionary\n",
    "s2[\"value5\"] = 405\n",
    "\n",
    "#And modifying value1\n",
    "s2[\"value1\"] = 40\n",
    "\n",
    "print(\"\\nAfter manipulation:\\n\")\n",
    "print(s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also easily manipulate all of the items in a series\n",
    "\n",
    "# We can add numbers to our values\n",
    "sAdd = s2+100\n",
    "print(\"After addition:\\n\", sAdd)\n",
    "\n",
    "# Subtract values\n",
    "sSubtract = s2-73\n",
    "print(\"\\nAfter subtraction:\\n\", sSubtract)\n",
    "\n",
    "# Do multiplication and division\n",
    "sFloat = s2*2/1.3\n",
    "print(\"\\nAfter multiplication and division:\\n\", sFloat)\n",
    "\n",
    "# You can also use series in logical expressions to generate boolean series\n",
    "sBool = s2 >500\n",
    "print(\"\\nBoolean indicating which values in the original series are >500:\\n\", sBool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can even use these logical expressions in order to generate subset series\n",
    "# only containing the values that meet a particular criteria\n",
    "sUnder500 = s2[s2<500]\n",
    "print(sUnder500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1.1\n",
    "## 1. Using the two lists in the next cell as a starting place, generate a series called \"counts\" with the names as labels and the values as the values. \n",
    "## 2. Generate a pandas series called \"norm\" by dividng the values in the \"counts\" series by 253,449 and then multiplying by 1,000,000.\n",
    "## 3. Generate a series called 'above1000' that only contains values from 'norm' that are >1000.\n",
    "## Print the length of both 'counts' and 'above1000'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"NS30_000000\", \"NS30_000001\", \"NS30_000002\", \"NS30_000003\", \"NS30_000004\", \"NS30_000005\", \"NS30_000006\", \"NS30_000007\", \"NS30_000008\", \"NS30_000009\", \"NS30_000010\", \"NS30_000011\", \"NS30_000012\", \"NS30_000013\", \"NS30_000014\", \"NS30_000015\", \"NS30_000016\", \"NS30_000017\", \"NS30_000018\", \"NS30_000019\", \"NS30_000020\", \"NS30_000021\", \"NS30_000022\", \"NS30_000023\", \"NS30_000024\", \"NS30_000025\", \"NS30_000026\", \"NS30_000027\", \"NS30_000028\", \"NS30_000029\", \"NS30_000030\", \"NS30_000031\", \"NS30_000032\", \"NS30_000033\", \"NS30_000034\", \"NS30_000035\", \"NS30_000036\", \"NS30_000037\", \"NS30_000038\", \"NS30_000039\", \"NS30_000040\", \"NS30_000041\", \"NS30_000042\", \"NS30_000043\", \"NS30_000044\", \"NS30_000045\", \"NS30_000046\", \"NS30_000047\", \"NS30_000048\", \"NS30_000049\", \"NS30_000050\", \"NS30_000051\", \"NS30_000052\", \"NS30_000053\", \"NS30_000054\", \"NS30_000055\", \"NS30_000056\", \"NS30_000057\", \"NS30_000058\", \"NS30_000059\", \"NS30_000060\", \"NS30_000061\", \"NS30_000062\", \"NS30_000063\", \"NS30_000064\", \"NS30_000065\", \"NS30_000066\", \"NS30_000067\", \"NS30_000068\", \"NS30_000069\", \"NS30_000070\", \"NS30_000071\", \"NS30_000072\", \"NS30_000073\", \"NS30_000074\", \"NS30_000075\", \"NS30_000076\", \"NS30_000077\", \"NS30_000078\", \"NS30_000079\", \"NS30_000080\", \"NS30_000081\", \"NS30_000082\", \"NS30_000083\", \"NS30_000084\", \"NS30_000085\", \"NS30_000086\", \"NS30_000087\", \"NS30_000088\", \"NS30_000089\", \"NS30_000090\", \"NS30_000091\", \"NS30_000092\", \"NS30_000093\", \"NS30_000094\", \"NS30_000095\", \"NS30_000096\", \"NS30_000097\", \"NS30_000098\", \"NS30_000099\", \"NS30_000100\", \"NS30_000101\", \"NS30_000102\", \"NS30_000103\", \"NS30_000104\", \"NS30_000105\", \"NS30_000106\", \"NS30_000107\", \"NS30_000108\", \"NS30_000109\", \"NS30_000110\", \"NS30_000111\", \"NS30_000112\", \"NS30_000113\", \"NS30_000114\", \"NS30_000115\", \"NS30_000116\", \"NS30_000117\", \"NS30_000118\", \"NS30_000119\", \"NS30_000120\"]\n",
    "values = [8828, 120, 137, 3, 8, 90, 270, 213, 1449, 65, 40, 77, 539, 398, 72, 6, 15, 2199, 15, 10159, 3815, 58, 4197, 2, 2862, 15, 142, 32, 1, 19, 597, 2, 305, 15, 116, 0, 5285, 897, 127, 62, 61, 15, 219, 2, 137, 2, 3, 9, 763, 3107, 1045, 154, 1, 2961, 930, 201, 90, 10, 97, 300, 10, 25, 52, 4, 17, 327, 115, 12, 966, 24, 14, 113, 5966, 614, 1728, 186, 7, 5, 5, 58, 18, 92, 59, 86, 43, 2414, 12, 19, 3, 6028, 45, 281, 17, 17, 41, 213, 2823, 9, 462, 18, 237, 8, 120, 4, 3, 34, 124, 296, 808, 27, 28, 9, 146, 25, 1, 65, 9, 26, 46, 13, 602]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes\n",
    "\n",
    "## Dataframes are 2-dimensional, labeled data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many ways to generate dataframes\n",
    "# However, for scientists, one of the most common approaches is to \n",
    "# read in a data file as a dataframe for further processing/analysis\n",
    "# This can be done using the read_csv function\n",
    "\n",
    "# Here, I'm reading in the data set used as an example in lecture\n",
    "# This is a tab delimited file with a header row and a column containing indexes\n",
    "df = pd.read_csv(\"Demo/cities.tsv\", sep=\"\\t\", header=0, index_col=0)\n",
    "\n",
    "#Let's take a look inside\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can access a whole column the same way you would access a value from a dictionary\n",
    "# Note that what is returned is a Series\n",
    "\n",
    "print(\"Population sizes:\\n\", df[\"Population\"])\n",
    "print(\"\\nElevations:\\n\", df[\"Elevation\"])\n",
    "print(\"\\nLatitudes:\\n\", df[\"Latitude\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also access the same info using dot notation\n",
    "\n",
    "print(\"Population sizes:\\n\", df.Population)\n",
    "print(\"\\nElevations:\\n\", df.Elevation)\n",
    "print(\"\\nLatitudes:\\n\", df.Latitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, we can access rows using the .loc property\n",
    "# Again, this returns a Series\n",
    "\n",
    "print(\"Data for Flagstaff:\\n\", df.loc[\"Flagstaff\"])\n",
    "print(\"\\nData for St. Louis:\\n\", df.loc[\"St. Louis\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we can also access specific items using a combination of column and row names\n",
    "\n",
    "print(\"Elevation for Flagstaff:\\n\", df[\"Elevation\"][\"Flagstaff\"])\n",
    "print(\"\\nElevation for St. Louis:\\n\", df.loc[\"St. Louis\"][\"Elevation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a lot of additional built-in methods for dataframes\n",
    "# One that is pretty useful is the .sum() method, which can be used to generate sums across columns or rows\n",
    "\n",
    "colSums = df.sum(axis=0)\n",
    "print(\"Column sums:\\n\", colSums)\n",
    "rowSums = df.sum(axis=1)\n",
    "print(\"\\nRow sums:\\n\", colSums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is also a built-in method for generating averages\n",
    "# Let's use this to convert from absolute values into deviations from the average\n",
    "\n",
    "colAvg = df.mean(axis=0)        #Here, we generate the averages for each column\n",
    "print(\"Column means:\\n\", colAvg, \"\\n\")\n",
    "\n",
    "df_deviation = df/colAvg        #Now, we divide each value by the average for that column\n",
    "df_deviation.head()             #Values >1 are higher than average, those <1 are lower than average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also generate a new data frame with a subset of the data rows\n",
    "# For example, by choosing only those with below average population size\n",
    "\n",
    "lowPop = df[\"Population\"]<colAvg[\"Population\"]\n",
    "dfLowPop = df[lowPop]\n",
    "print(\"Cities with lower than average population sizes:\\n\", dfLowPop)\n",
    "\n",
    "# or below average population size AND Elevation\n",
    "\n",
    "lowElev = dfLowPop[\"Elevation\"]<colAvg[\"Elevation\"]\n",
    "dfLow2 = dfLowPop[lowElev]\n",
    "print(\"Cities with lower than average population sizes and Elevations:\\n\", dfLow2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1.2\n",
    "## In the assignment directory for this week, you will find a file called 'pepSeqCounts.tsv'. This file contains raw count data from a highly-multiplexed serology assay, with each column (except the 1st) representing samples and each row (except the 1st) representing a different peptide antigen. \n",
    "### 1. Generate a pandas dataframe from this file, using the first row as the column names and the first column as the index names. \n",
    "### 2. Use the 'sum' method of your dataframe to generate a series that will contain the sum of the raw read counts for each sample (i.e., column sums). \n",
    "### 3. Use the series from step 2 to normalize the entire dataframe, converting from raw read counts to reads per million mapped (raw count/column sum\\*1,000,000).\n",
    "### 4. Print the normalized values for each of the following sample/peptide combos:\n",
    "#### BB006_A, NS30_000783\n",
    "#### BB010_B, NS30_000456\n",
    "#### BB019_B, NS30_000076\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1.3\n",
    "## The 'pepSeqCounts.tsv' file actually contains two replicates for each sample, with these being distinguishable by their extensions: \\_A and \\_B. \n",
    "## Generate a new, empty pandas dataframe and add three columns to this dataframe:\n",
    "### BB013\n",
    "### BB404\n",
    "### BB413\n",
    "\n",
    "### Each of these columns should contain the average normalized read counts of the two appropriate replicates. \n",
    "\n",
    "### Use the 'head' method to print the first 5 rows of your new dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
